{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed86aefc-f6d0-455d-9aef-bc0b5681cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from random import randrange\n",
    "from tqdm import tqdm, tnrange\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.optimizer_v2.gradient_descent import SGD\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Dense, MaxPooling2D, Flatten, Conv2D, Lambda, Dropout, LeakyReLU, BatchNormalization, Activation, AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from mlxtend.evaluate import accuracy\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD, Nadam\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5a213c9-c03b-4f1b-a3a0-6e5333383da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # ignore tensorflow warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba48d5e6-43f0-4a79-bdf1-366aac61855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"data/NIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ce62474-4908-4ad6-8814-4b41795aa7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6000 files belonging to 500 classes.\n",
      "Using 4800 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    path_data,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=1007,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0fbd595-42be-40bb-859c-9090d02a838d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6000 files belonging to 500 classes.\n",
      "Using 900 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    path_data,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=1007,\n",
    "    validation_split=0.15,\n",
    "    subset=\"validation\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0790bf7-e934-411a-a916-cc9be1801f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6000 files belonging to 500 classes.\n",
      "Using 900 files for validation.\n"
     ]
    }
   ],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    path_data,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=1007,\n",
    "    validation_split=0.15,\n",
    "    subset=\"validation\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9402b5c-c092-4e97-9e4b-8fdc1510d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "\n",
    "def resnet_model_tf(input_shape=(128, 128, 3), nombre_classes=500):\n",
    "    resnet = VGG19(weights=None, include_top=False, input_shape=input_shape)\n",
    "    resnet.tbatch_sizenable = False\n",
    "    model = Sequential()\n",
    "    model.add(resnet)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='LeakyReLU'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='LeakyReLU'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nombre_classes, activation='softmax'))\n",
    "    \n",
    "    print(model.summary())\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=2, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.7, \n",
    "                                            min_lr=0.00000000001)\n",
    "    return model, learning_rate_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33afcb1f-8954-4f2c-82fc-c45854989d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg19 (Functional)          (None, 4, 4, 512)         20024384  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              33558528  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 500)               2048500   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,412,724\n",
      "Trainable params: 72,412,724\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model, learning_rate_reduction = resnet_model_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c38539-3f7c-40d1-a98c-00401c8b6d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ================= Training : RESNET model ================= \n",
      "\n",
      "             Epochs :  20   |   Batch size : 32 \n",
      "\n",
      " =========================================================== \n",
      "\n",
      "Epoch 1/20\n",
      "150/150 [==============================] - 39s 225ms/step - loss: 27.7993 - accuracy: 8.3333e-04 - val_loss: 6.2199 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 33s 221ms/step - loss: 6.2181 - accuracy: 0.0010 - val_loss: 6.2296 - val_accuracy: 0.0011 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 33s 221ms/step - loss: 6.2092 - accuracy: 0.0035 - val_loss: 6.2444 - val_accuracy: 0.0011 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - ETA: 0s - loss: 6.2088 - accuracy: 0.0019\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "150/150 [==============================] - 33s 222ms/step - loss: 6.2088 - accuracy: 0.0019 - val_loss: 6.2623 - val_accuracy: 0.0011 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 33s 221ms/step - loss: 6.2191 - accuracy: 0.0015 - val_loss: 6.2795 - val_accuracy: 0.0011 - lr: 7.0000e-04\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - ETA: 0s - loss: 6.2165 - accuracy: 0.0019\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "150/150 [==============================] - 33s 221ms/step - loss: 6.2165 - accuracy: 0.0019 - val_loss: 6.2799 - val_accuracy: 0.0011 - lr: 7.0000e-04\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 33s 222ms/step - loss: 6.2204 - accuracy: 0.0019 - val_loss: 6.2741 - val_accuracy: 0.0011 - lr: 4.9000e-04\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - ETA: 0s - loss: 6.2137 - accuracy: 0.0019\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "150/150 [==============================] - 33s 220ms/step - loss: 6.2137 - accuracy: 0.0019 - val_loss: 6.2751 - val_accuracy: 0.0011 - lr: 4.9000e-04\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 33s 220ms/step - loss: 6.2139 - accuracy: 0.0025 - val_loss: 6.2795 - val_accuracy: 0.0011 - lr: 3.4300e-04\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - ETA: 0s - loss: 6.2142 - accuracy: 0.0023\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "150/150 [==============================] - 33s 221ms/step - loss: 6.2142 - accuracy: 0.0023 - val_loss: 6.2813 - val_accuracy: 0.0011 - lr: 3.4300e-04\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 33s 220ms/step - loss: 6.2139 - accuracy: 8.3333e-04 - val_loss: 6.2850 - val_accuracy: 0.0011 - lr: 2.4010e-04\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - ETA: 0s - loss: 6.2123 - accuracy: 0.0015\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "150/150 [==============================] - 33s 222ms/step - loss: 6.2123 - accuracy: 0.0015 - val_loss: 6.2876 - val_accuracy: 0.0011 - lr: 2.4010e-04\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 33s 221ms/step - loss: 6.2110 - accuracy: 0.0023 - val_loss: 6.2924 - val_accuracy: 0.0000e+00 - lr: 1.6807e-04\n",
      "Epoch 14/20\n",
      "150/150 [==============================] - ETA: 0s - loss: 6.2106 - accuracy: 0.0027\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "150/150 [==============================] - 33s 221ms/step - loss: 6.2106 - accuracy: 0.0027 - val_loss: 6.2945 - val_accuracy: 0.0000e+00 - lr: 1.6807e-04\n",
      "Epoch 15/20\n",
      "150/150 [==============================] - 33s 221ms/step - loss: 6.2090 - accuracy: 0.0021 - val_loss: 6.2967 - val_accuracy: 0.0000e+00 - lr: 1.1765e-04\n",
      "Epoch 16/20\n",
      "150/150 [==============================] - ETA: 0s - loss: 6.2092 - accuracy: 0.0023\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 8.235429777414538e-05.\n",
      "150/150 [==============================] - 33s 221ms/step - loss: 6.2092 - accuracy: 0.0023 - val_loss: 6.2986 - val_accuracy: 0.0000e+00 - lr: 1.1765e-04\n",
      "Epoch 17/20\n",
      "150/150 [==============================] - 33s 221ms/step - loss: 6.2074 - accuracy: 0.0019 - val_loss: 6.3003 - val_accuracy: 0.0000e+00 - lr: 8.2354e-05\n",
      "Epoch 18/20\n",
      "150/150 [==============================] - ETA: 0s - loss: 6.2080 - accuracy: 0.0035\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 5.76480058953166e-05.\n",
      "150/150 [==============================] - 33s 221ms/step - loss: 6.2080 - accuracy: 0.0035 - val_loss: 6.3013 - val_accuracy: 0.0000e+00 - lr: 8.2354e-05\n",
      "Epoch 19/20\n",
      " 50/150 [=========>....................] - ETA: 21s - loss: 6.2114 - accuracy: 6.2500e-04"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch = 32\n",
    "\n",
    "print(\"\\n ================= Training : RESNET model ================= \\n\")\n",
    "print(\"             Epochs :  {}   |   Batch size : {} \".format(epochs, batch))\n",
    "print(\"\\n =========================================================== \\n\")\n",
    "trained = model.fit(train_ds, validation_data = val_ds, epochs=epochs, batch_size=batch, callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2908ddf-2556-4a4e-8dbf-ec5814608aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = model.evaluate(test_ds)\n",
    "input_shape = (128, 128, 3)\n",
    "\n",
    "print(\"\\n ================= Evaluation : Resnet model ================= \\n\")\n",
    "print(\"  With : \\n\")\n",
    "print(\"Batch size         :  {}     |   Epochs      : {} \".format(batch, epochs))\n",
    "print(\"Nombres de classes :  {}    |   Input shape : {} \\n\".format(len(train_ds.class_names), input_shape))\n",
    "print(\"\\n ============================================================= \\n\")\n",
    "\n",
    "print(\"  Results : \\n\")\n",
    "print(\"Loss  : %.2f%%\" % (val[0] * 100))\n",
    "print(\"Score : %.2f%%\" % (val[1] * 100))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0d18fcc-aaae-409f-84d4-ba39d95ac4c8",
   "metadata": {},
   "source": [
    "!mkdir -p saved_model\n",
    "model.save('saved_model/vgg19.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da67ed0-c8fe-46ff-8f85-f7f6c928399e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77acffe-b5f6-45a7-ae31-4c51c2fafb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(train):\n",
    "    accuracy = train.history['accuracy']\n",
    "    val_accuracy = train.history['val_accuracy']\n",
    "    epochs = range(len(accuracy))\n",
    "    plt.plot(epochs, accuracy, 'b', label='Score apprentissage')\n",
    "    plt.plot(epochs, val_accuracy, 'r', label='Score validation')\n",
    "    plt.title('Scores')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "def plot_loss(train):\n",
    "    loss = train.history['loss']\n",
    "    val_loss = train.history['val_loss']\n",
    "    epochs = range(len(loss))\n",
    "    plt.plot(epochs, loss, 'b', label='Loss apprentissage')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Loss validation')\n",
    "    plt.title('Scores')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_scores(trained)\n",
    "plot_loss(trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74de6eef-daa1-4f6f-809f-eae817e70bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
